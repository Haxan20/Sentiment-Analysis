{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000ff035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086948f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiments= pipeline(task= 'sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1e0f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998830556869507}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text= 'I absolutely love this product. it exceeded all my expectations!'\n",
    "result= sentiments(sample_text)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99bf50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:I absolutely love this product. It exceeded all my expectations!\n",
      "Prediction: {'label': 'POSITIVE', 'score': 0.9998830556869507}\n",
      "\n",
      "Text:The battery life is terrible. I regret buying it.\n",
      "Prediction: {'label': 'NEGATIVE', 'score': 0.9996052384376526}\n",
      "\n",
      "Text:It's okay, not great but not awful either.\n",
      "Prediction: {'label': 'POSITIVE', 'score': 0.9743938446044922}\n",
      "\n",
      "Text:I'm not sure this is what I want.\n",
      "Prediction: {'label': 'NEGATIVE', 'score': 0.9988991022109985}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text2= [\"I absolutely love this product. It exceeded all my expectations!\",\n",
    "    \"The battery life is terrible. I regret buying it.\",\n",
    "    \"It's okay, not great but not awful either.\",\n",
    "    \"I'm not sure this is what I want.\"]\n",
    "\n",
    "result2= sentiments(sample_text2)\n",
    "for text, result in zip (sample_text2, result2):\n",
    "    print(f'Text:{text}\\nPrediction: {result}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fd4b1",
   "metadata": {},
   "source": [
    "Loading a Specific Model from the Model Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f47c91",
   "metadata": {},
   "source": [
    "In the previous example, we used the default model for the specified task. However, if we decide to use a model of our own choosing, we can do so. We simply need to specify the model's name when instantiating the pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c11009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name= 'siebert/sentiment-roberta-large-english'\n",
    "sentimental_=pipeline(task='sentiment-analysis', model=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "119ee611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:I absolutely love this product. It exceeded all my expectations! \n",
      "Prediction:{'label': 'POSITIVE', 'score': 0.9998830556869507}\n",
      "\n",
      "Text:The battery life is terrible. I regret buying it. \n",
      "Prediction:{'label': 'NEGATIVE', 'score': 0.9996052384376526}\n",
      "\n",
      "Text:It's okay, not great but not awful either. \n",
      "Prediction:{'label': 'POSITIVE', 'score': 0.9743938446044922}\n",
      "\n",
      "Text:I'm not sure this is what I want. \n",
      "Prediction:{'label': 'NEGATIVE', 'score': 0.9988991022109985}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results= sentimental_(sample_text2)\n",
    "for text, result in zip(sample_text2, result2):\n",
    "    print(f'Text:{text} \\nPrediction:{result}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67a7c5",
   "metadata": {},
   "source": [
    "Topic Classification with Pretrained Models in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef6ace",
   "metadata": {},
   "source": [
    "Topic Classification (also known as topic labeling or content classification) - a technique used to assign predefined topics or categories, such as weather, sports, finance, and more, to a given piece of text. This approach is particularly useful for organizing and filtering large streams of textual data, such as news feeds or social media posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff4fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let reduce the log verbosity of the transformers package. \n",
    "# this ensures that we only get eror alerts but not information log\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb40e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9332ab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'environment', 'score': 0.9890682101249695}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_TIMEOUT\"] = \"60\"  # increase timeout to 60 seconds\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'classla/multilingual-IPTC-news-topic-classifier'\n",
    "topics = pipeline(task='text-classification', model=model_name, trust_remote_code=True)\n",
    "\n",
    "print(topics(\"Climate change is impacting global agriculture.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3473303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Government announces new economic stimulus plan to boost small businesses.\n",
      "Prediction: {'label': 'economy, business and finance', 'score': 0.9973300695419312}\n",
      "\n",
      "Text: Local football team wins national championship after a thrilling final match.\n",
      "Prediction: {'label': 'sport', 'score': 0.9945080876350403}\n",
      "\n",
      "Text: Scientists discover potential treatment for a rare genetic disease.\n",
      "Prediction: {'label': 'science and technology', 'score': 0.6113675236701965}\n",
      "\n",
      "Text: Tech giant reveals latest smartphone model with advanced AI features.\n",
      "Prediction: {'label': 'science and technology', 'score': 0.9872331619262695}\n",
      "\n",
      "Text: Widespread protests erupt over environmental concerns and climate policies.\n",
      "Prediction: {'label': 'environment', 'score': 0.9902381300926208}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"Government announces new economic stimulus plan to boost small businesses.\",\n",
    "    \"Local football team wins national championship after a thrilling final match.\",\n",
    "    \"Scientists discover potential treatment for a rare genetic disease.\",\n",
    "    \"Tech giant reveals latest smartphone model with advanced AI features.\",\n",
    "    \"Widespread protests erupt over environmental concerns and climate policies.\",\n",
    "]\n",
    "\n",
    "results= topics(sample_texts)\n",
    "for text, result in zip(sample_texts,results):\n",
    "    print(f'Text: {text}\\nPrediction: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef4875d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: NASA Announces Ambitious Plans for Lunar Base Construction\n",
      "Prediction: {'label': 'science and technology', 'score': 0.9767311811447144}\n",
      "\n",
      "Text: Global Markets Rally as Inflation Slows for Second Consecutive Quarter\n",
      "Prediction: {'label': 'economy, business and finance', 'score': 0.9981062412261963}\n",
      "\n",
      "Text: Scientists Develop Breakthrough Gene Therapy for Rare Blood Disorders\n",
      "Prediction: {'label': 'science and technology', 'score': 0.9227041602134705}\n",
      "\n",
      "Text: Electric Vehicle Sales Surge Amid Growing Climate Concerns\n",
      "Prediction: {'label': 'environment', 'score': 0.9906734824180603}\n",
      "\n",
      "Text: Historic Artifacts Discovered in Ancient Egyptian Tomb\n",
      "Prediction: {'label': 'arts, culture, entertainment and media', 'score': 0.9908339381217957}\n",
      "\n",
      "Text: Tech Giants Face New Regulations on User Data Privacy in Europe\n",
      "Prediction: {'label': 'science and technology', 'score': 0.4992971122264862}\n",
      "\n",
      "Text: World Cup Underdogs Stun Defending Champions in Dramatic Upset\n",
      "Prediction: {'label': 'sport', 'score': 0.993782103061676}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let try other examples\n",
    "sample2 = [\n",
    "    \"NASA Announces Ambitious Plans for Lunar Base Construction\",\n",
    "    \"Global Markets Rally as Inflation Slows for Second Consecutive Quarter\",\n",
    "    \"Scientists Develop Breakthrough Gene Therapy for Rare Blood Disorders\",\n",
    "    \"Electric Vehicle Sales Surge Amid Growing Climate Concerns\",\n",
    "    \"Historic Artifacts Discovered in Ancient Egyptian Tomb\",\n",
    "    \"Tech Giants Face New Regulations on User Data Privacy in Europe\",\n",
    "    \"World Cup Underdogs Stun Defending Champions in Dramatic Upset\",\n",
    "]    \n",
    " \n",
    "resalt= topics(sample2)\n",
    "for text2, resultA in zip(sample2,resalt):\n",
    "    print(f'Text: {text2}\\nPrediction: {resultA}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d66b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
